"use strict";
//#region rolldown:runtime
var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __copyProps = (to, from, except, desc) => {
	if (from && typeof from === "object" || typeof from === "function") for (var keys = __getOwnPropNames(from), i = 0, n = keys.length, key; i < n; i++) {
		key = keys[i];
		if (!__hasOwnProp.call(to, key) && key !== except) __defProp(to, key, {
			get: ((k) => from[k]).bind(null, key),
			enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable
		});
	}
	return to;
};
var __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", {
	value: mod,
	enumerable: true
}) : target, mod));

//#endregion
const path = __toESM(require("path"));
const fs = __toESM(require("fs"));
const url = __toESM(require("url"));
const __jridgewell_sourcemap_codec = __toESM(require("@jridgewell/sourcemap-codec"));
const __ampproject_remapping = __toESM(require("@ampproject/remapping"));
const zlib = __toESM(require("zlib"));

//#region ../load-source-map/dist/index.mjs
/**
* Strip any JSON XSSI avoidance prefix from the string (as documented in the source maps specification),
* and parses the string as JSON.
*
* https://github.com/mozilla/source-map/blob/3cb92cc3b73bfab27c146bae4ef2bc09dbb4e5ed/lib/util.js#L162-L164
*/
function parseSourceMapInput(str) {
	return JSON.parse(str.replace(/^\)]}'[^\n]*\n/, ""));
}
/**
sourceMappingURL=data:application/json;charset=utf-8;base64,data
sourceMappingURL=data:application/json;base64,data
sourceMappingURL=data:application/json;uri,data
sourceMappingURL=map-file-comment.css.map
sourceMappingURL=map-file-comment.css.map?query=value
*/
const sourceMappingRegExp = /[@#]\s*sourceMappingURL=(\S+)\b/g;
/**
* Checks if the given path is a file.
*/
function isFile(path$1) {
	try {
		return (0, fs.statSync)(path$1).isFile();
	} catch {
		return false;
	}
}
function loadCodeAndMap(codePath, sourcesPathNormalizer) {
	if (!isFile(codePath)) return null;
	const code = (0, fs.readFileSync)(codePath, "utf-8");
	const extractedComment = code.includes("sourceMappingURL") && Array.from(code.matchAll(sourceMappingRegExp)).at(-1);
	if (!extractedComment || !extractedComment.length) return { code };
	const maybeMap = loadMap(codePath, extractedComment[1]);
	if (!maybeMap) return { code };
	const { map, mapPath } = maybeMap;
	const mapDir = (0, path.dirname)(mapPath);
	sourcesPathNormalizer ??= (path$1) => (0, path.isAbsolute)(path$1) ? path$1 : (0, path.resolve)(mapDir, map.sourceRoot ?? ".", path$1);
	map.sources = normalizeSourcesPaths(map, sourcesPathNormalizer);
	map.sourcesContent = loadMissingSourcesContent(map);
	delete map.sourceRoot;
	return {
		code,
		map
	};
}
function loadMap(codePath, sourceMappingURL) {
	if (sourceMappingURL.startsWith("data:")) {
		const map = parseDataUrl(sourceMappingURL);
		return {
			map: parseSourceMapInput(map),
			mapPath: codePath
		};
	}
	const sourceMapFilename = new URL(sourceMappingURL, "file://").pathname;
	const mapPath = (0, path.join)((0, path.dirname)(codePath), sourceMapFilename);
	if (!(0, fs.existsSync)(mapPath)) return null;
	return {
		map: parseSourceMapInput((0, fs.readFileSync)(mapPath, "utf-8")),
		mapPath
	};
}
function parseDataUrl(url$1) {
	const [prefix, payload] = url$1.split(",");
	const encoding = prefix.split(";").at(-1);
	switch (encoding) {
		case "base64": return Buffer.from(payload, "base64").toString();
		case "uri": return decodeURIComponent(payload);
		default: throw new Error("Unsupported source map encoding: " + encoding);
	}
}
/**
* Normalize the paths of the sources in the source map to be absolute paths.
*/
function normalizeSourcesPaths(map, sourcesPathNormalizer) {
	return map.sources.map((source) => source ? sourcesPathNormalizer(source) : null);
}
/**
* Loop through the sources and try to load missing `sourcesContent` from the file system.
*/
function loadMissingSourcesContent(map) {
	return map.sources.map((source, index) => {
		if (map.sourcesContent?.[index]) return map.sourcesContent[index];
		if (source && (0, fs.existsSync)(source)) return (0, fs.readFileSync)(source, "utf-8");
		return null;
	});
}

//#endregion
//#region src/utils.ts
const esmRegex = /\.m[tj]sx?$/;
const cjsRegex = /\.c[tj]sx?$/;
const jsRegexp = /\.[cm]?[tj]s[x]?$/;
function normalizeOptions(options) {
	const format$1 = options?.format || options?.filename?.split(".").at(-1) || "html";
	const defaultOptions = {
		enabled: true,
		format: format$1,
		filename: "sonda-report." + format$1,
		open: true,
		detailed: false,
		sources: false,
		gzip: false,
		brotli: false,
		sourcesPathNormalizer: null
	};
	const normalizedOptions = Object.assign({}, defaultOptions, options);
	normalizedOptions.filename = normalizeOutputPath(normalizedOptions);
	return normalizedOptions;
}
function normalizePath(pathToNormalize) {
	const normalized = pathToNormalize.replace(/^\0/, "");
	const relativized = (0, path.relative)(process.cwd(), normalized);
	return relativized.replaceAll(path.win32.sep, path.posix.sep);
}
function normalizeOutputPath(options) {
	let path$1 = options.filename;
	const expectedExtension = "." + options.format;
	if (!(0, path.isAbsolute)(path$1)) path$1 = (0, path.join)(process.cwd(), path$1);
	if (expectedExtension !== (0, path.extname)(path$1)) {
		console.warn("\x1B[0;33m" + `Sonda: The file extension specified in the 'filename' does not match the 'format' option. ` + `The extension will be changed to '${expectedExtension}'.`);
		path$1 = (0, path.format)({
			...(0, path.parse)(path$1),
			base: "",
			ext: expectedExtension
		});
	}
	return path$1;
}

//#endregion
//#region src/sourcemap/map.ts
function mapSourceMap(map, dirPath, inputs) {
	const alreadyRemapped = new Set();
	const remapped = (0, __ampproject_remapping.default)(map, (file, ctx) => {
		if (alreadyRemapped.has(file)) return;
		alreadyRemapped.add(file);
		const codeMap = addSourcesToInputs((0, path.resolve)(dirPath, file), inputs);
		if (!codeMap) return;
		ctx.content ??= codeMap.code;
		return codeMap.map;
	}, { decodedMappings: true });
	return remapped;
}
function addSourcesToInputs(path$1, inputs) {
	const codeMap = loadCodeAndMap(path$1);
	if (!codeMap) return null;
	const parentPath = normalizePath(path$1);
	const format$1 = inputs[parentPath]?.format ?? "unknown";
	codeMap.map?.sources.filter((source) => source !== null).forEach((source, index) => {
		const normalizedPath = normalizePath(source);
		if (parentPath === normalizedPath) return;
		inputs[normalizedPath] = {
			bytes: Buffer.byteLength(codeMap.map.sourcesContent?.[index] ?? ""),
			format: format$1,
			imports: [],
			belongsTo: parentPath
		};
	});
	return codeMap;
}

//#endregion
//#region src/sourcemap/bytes.ts
const UNASSIGNED = "[unassigned]";
function getBytesPerSource(code, map, assetSizes, options) {
	const contributions = getContributions(map.sources);
	const codeLines = code.split(/(?<=\r?\n)/);
	for (let lineIndex = 0; lineIndex < codeLines.length; lineIndex++) {
		const lineCode = codeLines[lineIndex];
		const mappings = map.mappings[lineIndex] || [];
		let currentColumn = 0;
		for (let i = 0; i <= mappings.length; i++) {
			const mapping = mappings[i];
			const startColumn = mapping?.[0] ?? lineCode.length;
			const endColumn = mappings[i + 1]?.[0] ?? lineCode.length;
			if (startColumn > currentColumn) contributions.set(UNASSIGNED, contributions.get(UNASSIGNED) + lineCode.slice(currentColumn, startColumn));
			if (mapping) {
				const sourceIndex = mapping?.[1];
				const codeSlice = lineCode.slice(startColumn, endColumn);
				const source = sourceIndex !== undefined && map.sources[sourceIndex] || UNASSIGNED;
				contributions.set(source, contributions.get(source) + codeSlice);
				currentColumn = endColumn;
			} else currentColumn = startColumn;
		}
	}
	const sourceSizes = new Map();
	const contributionsSum = {
		uncompressed: 0,
		gzip: 0,
		brotli: 0
	};
	for (const [source, codeSegment] of contributions) {
		const sizes = getSizes(codeSegment, options);
		contributionsSum.uncompressed += sizes.uncompressed;
		contributionsSum.gzip += sizes.gzip;
		contributionsSum.brotli += sizes.brotli;
		sourceSizes.set(source, sizes);
	}
	return adjustSizes(sourceSizes, assetSizes, contributionsSum, options);
}
function getSizes(code, options) {
	return {
		uncompressed: Buffer.byteLength(code),
		gzip: options.gzip ? (0, zlib.gzipSync)(code).length : 0,
		brotli: options.brotli ? (0, zlib.brotliCompressSync)(code).length : 0
	};
}
function getContributions(sources) {
	const contributions = new Map();
	sources.filter((source) => source !== null).forEach((source) => contributions.set(source, ""));
	contributions.set(UNASSIGNED, "");
	return contributions;
}
/**
* Compression efficiency improves with the size of the file.
*
* However, what we have is the compressed size of the entire bundle (`actual`),
* the sum of all files compressed individually (`sum`) and the compressed
* size of a given file (`content`). The last value is essentially a “worst-case”
* scenario, and the actual size of the file in the bundle is likely to be smaller.
*
* We use this information to estimate the actual size of the file in the bundle
* after compression.
*/
function adjustSizes(sources, asset, sums, options) {
	const gzipDelta = options.gzip ? asset.gzip / sums.gzip : 0;
	const brotliDelta = options.brotli ? asset.brotli / sums.brotli : 0;
	for (const [source, sizes] of sources) sources.set(source, {
		uncompressed: sizes.uncompressed,
		gzip: options.gzip ? Math.round(sizes.gzip * gzipDelta) : 0,
		brotli: options.brotli ? Math.round(sizes.brotli * brotliDelta) : 0
	});
	return sources;
}

//#endregion
//#region src/report/formats.ts
function generateJsonReport(assets, inputs, options) {
	const acceptedExtensions = [
		".js",
		".mjs",
		".cjs",
		".css"
	];
	const outputs = assets.filter((asset) => acceptedExtensions.includes((0, path.extname)(asset))).reduce((carry, asset) => {
		const data = processAsset(asset, inputs, options);
		if (data) carry[normalizePath(asset)] = data;
		return carry;
	}, {});
	return {
		inputs: sortObjectKeys(inputs),
		outputs: sortObjectKeys(outputs)
	};
}
function generateHtmlReport(assets, inputs, options) {
	const json = generateJsonReport(assets, inputs, options);
	const __dirname$1 = (0, path.dirname)((0, url.fileURLToPath)(require("url").pathToFileURL(__filename).href));
	const template = (0, fs.readFileSync)((0, path.resolve)(__dirname$1, "./index.html"), "utf-8");
	return template.replace("__REPORT_DATA__", encodeURIComponent(JSON.stringify(json)));
}
function processAsset(asset, inputs, options) {
	const maybeCodeMap = loadCodeAndMap(asset, options.sourcesPathNormalizer);
	if (!hasCodeAndMap(maybeCodeMap)) return;
	const { code, map } = maybeCodeMap;
	const mapped = options.detailed ? mapSourceMap(map, (0, path.dirname)(asset), inputs) : {
		...map,
		mappings: (0, __jridgewell_sourcemap_codec.decode)(map.mappings)
	};
	mapped.sources = mapped.sources.map((source) => source && normalizePath(source));
	const assetSizes = getSizes(code, options);
	const bytes = getBytesPerSource(code, mapped, assetSizes, options);
	const outputInputs = Array.from(bytes).reduce((carry, [source, sizes]) => {
		carry[normalizePath(source)] = sizes;
		return carry;
	}, {});
	return {
		...assetSizes,
		inputs: sortObjectKeys(outputInputs),
		map: options.sources ? {
			version: 3,
			names: [],
			mappings: mapped.mappings,
			sources: mapped.sources,
			sourcesContent: mapped.sourcesContent
		} : undefined
	};
}
function hasCodeAndMap(result) {
	return Boolean(result && result.code && result.map);
}
function sortObjectKeys(object) {
	return Object.keys(object).sort().reduce((carry, key) => {
		carry[key] = object[key];
		return carry;
	}, {});
}

//#endregion
//#region src/report/generate.ts
async function generateReportFromAssets(assets, inputs, pluginOptions) {
	const options = normalizeOptions(pluginOptions);
	const handler = options.format === "html" ? saveHtml : saveJson;
	const report = handler(assets, inputs, options);
	const outputDirectory = (0, path.dirname)(options.filename);
	if (!(0, fs.existsSync)(outputDirectory)) (0, fs.mkdirSync)(outputDirectory, { recursive: true });
	(0, fs.writeFileSync)(options.filename, report);
	if (!options.open) return;
	/**
	* `open` is ESM-only package, so we need to import it
	* dynamically to make it work in CommonJS environment.
	*/
	const { default: open } = await import("open");
	open(options.filename);
}
function saveHtml(assets, inputs, options) {
	return generateHtmlReport(assets, inputs, options);
}
function saveJson(assets, inputs, options) {
	const report = generateJsonReport(assets, inputs, options);
	return JSON.stringify(report, null, 2);
}

//#endregion
Object.defineProperty(exports, '__toESM', {
  enumerable: true,
  get: function () {
    return __toESM;
  }
});
Object.defineProperty(exports, 'addSourcesToInputs', {
  enumerable: true,
  get: function () {
    return addSourcesToInputs;
  }
});
Object.defineProperty(exports, 'cjsRegex', {
  enumerable: true,
  get: function () {
    return cjsRegex;
  }
});
Object.defineProperty(exports, 'esmRegex', {
  enumerable: true,
  get: function () {
    return esmRegex;
  }
});
Object.defineProperty(exports, 'generateReportFromAssets', {
  enumerable: true,
  get: function () {
    return generateReportFromAssets;
  }
});
Object.defineProperty(exports, 'jsRegexp', {
  enumerable: true,
  get: function () {
    return jsRegexp;
  }
});
Object.defineProperty(exports, 'normalizePath', {
  enumerable: true,
  get: function () {
    return normalizePath;
  }
});
//# sourceMappingURL=src.cjs.map